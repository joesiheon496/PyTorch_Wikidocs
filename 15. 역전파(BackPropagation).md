# 역전파(BackPropagation)
![image](https://github.com/joesiheon496/PyTorch_Wikidocs/assets/56191064/3fd6009d-4d00-496c-acca-32186f273daa)

- 은닉층과 출력층의 모든 뉴런에서 변수 $z$가 존재하는데 여기서 변수 $z$는 이전층의 모든 입력이 각각의 가중치와 곱해진 값들이 모두 더해진 가중합을 의미
-  이 값은 뉴런에서 아직 시그모이드 함수를 거치지 않은 상태
-  $z$ 우측의 $|$를 지나서 존재하는 변수 $h$또는 $\sigma$는 $z$가 시그모이드 함수를 지난 후의 값으로 각 뉴런의 출력값
