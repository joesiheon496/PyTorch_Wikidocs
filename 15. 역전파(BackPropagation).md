# 역전파(BackPropagation)
![image](https://github.com/joesiheon496/PyTorch_Wikidocs/assets/56191064/3fd6009d-4d00-496c-acca-32186f273daa)

- 은닉층과 출력층의 모든 뉴런에서 변수 $z$가 존재하는데 여기서 변수 $z$는 이전층의 모든 입력이 각각의 가중치와 곱해진 값들이 모두 더해진 가중합을 의미
-  이 값은 뉴런에서 아직 시그모이드 함수를 거치지 않은 상태
-  $z$ 우측의 $|$를 지나서 존재하는 변수 $h$또는 $\sigma$는 $z$가 시그모이드 함수를 지난 후의 값으로 각 뉴런의 출력값
# 순전파(Forward Propagation)
![image](https://github.com/joesiheon496/PyTorch_Wikidocs/assets/56191064/21dccb25-bc8a-4cae-99f4-f44a7b2982fb)
$$z_{1}=W_{1}x_{1} + W_{2}x_{2}=0.3 \text{×} 0.1 + 0.25 \text{×} 0.2= 0.08$$
$$z_{2}=W_{3}x_{1} + W_{4}x_{2}=0.4 \text{×} 0.1 + 0.35 \text{×} 0.2= 0.11$$

$$h_{1}=sigmoid(z_{1}) = 0.51998934$$
$$h_{2}=sigmoid(z_{2}) = 0.52747230$$

-시그모이드 함수가 리턴하는 결과값은 은닉층 뉴런의 최종 출력값입니다. 식에서는 각각 $z_3$과 $z_4$에 해당되며, 아래의 결과와 같습니다.
$$z_{3}=W_{5}h_{1}+W_{6}h_{2} = 0.45 \text{×} h_{1} + 0.4 \text{×} h_{2} = 0.44498412$$
$$z_{4}=W_{7}h_{1}+W_{8}h_{2} = 0.7 \text{×} h_{1} + 0.6 \text{×} h_{2} = 0.68047592$$

$$o_{1}=sigmoid(z_{3})=0.60944600$$
$$o_{2}=sigmoid(z_{4})=0.66384491$$

- 오차(Error)를 계산하기 위한 손실 함수(Loss function)로는 평균 제곱 오차 MSE를 사용

$$E_{o1}=\frac{1}{2}(target_{o1}-output_{o1})^{2}=0.02193381$$
$$E_{o2}=\frac{1}{2}(target_{o2}-output_{o2})^{2}=0.00203809$$
$$E_{total}=E_{o1}+E_{o2}=0.02397190$$

# 역전파 1단계(BackPropagation Step 1)
- 순전파가 입력층에서 출력층으로 향한다면 역전파는 반대로 출력층에서 입력층 방향으로 계산하면서 가중치를 업데이트
- 출력층 바로 이전의 은닉층을 N층이라고 하였을 때, 출력층과 N층 사이의 가중치를 업데이트하는 단계를 역전파 1단계
- N층과 N층의 이전층 사이의 가중치를 업데이트 하는 단계를 역전파 2단계
![image](https://github.com/joesiheon496/PyTorch_Wikidocs/assets/56191064/4a1edfcf-6786-4f65-8017-5435d53e3fe0)

- 역전파 1단계에서 업데이트 해야 할 가중치는 $W_{5}, W_{6}, W_{7}, W_{8}$  총 4개입니다. 원리 자체는 동일하므로 우선 $W_{5}$에 대해서 먼저 업데이트를 진행해보겠습니다. 경사 하강법을 수행하려면 가중치 $W_{5}$를 업데이트 하기 위해서 $\frac{∂E_{total}}{∂W_{5}}$를 계산

$\frac{∂E_{total}}{∂W_{5}}$ 계산하기 위해 미분의 연쇄 법칙(Chain rule)에 따라서 이와 같이 풀어 쓸 수 있습니다.
$$\frac{∂E_{total}}{∂W_{5}} = \frac{∂E_{total}}{∂o_{1}} \text{×} \frac{∂o_{1}}{∂z_{3}} \text{×} \frac{∂z_{3}}{∂W_{5}}$$
 
 

















