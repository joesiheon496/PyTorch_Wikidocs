```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

# 데이터
x_train = torch.FloatTensor([[73, 80, 75],
                            [93, 88, 93],
                            [89, 91, 80],
                            [96, 98, 100]])
y_train = torch.FloatTensor([[152],[185],[180],[196]])

# 모델 초기화
W = torch.zeros((4,1), requires_grad=True)
b = torch.zeros(1, required_grad = True)

# optimizer 설정
optimizer = optim.SGD([W,b], lr=1e-5)

nb_epochs = 20
for epoch in range(nb_epochs+1):
  # H(x) 계산
  # 편향 b는 브로드 캐스팅 되어 각 샘플에 더해진다
  hypothesis = x_train.matmul(W) + b
  
  # Cost 계산
  cost = torch.mean((hypothesis - y_train)**2)
  
  # cost로 H(x)계산
  optimizer.zero_grad()
  cost.backward()
  optimizer.step()
  
  print("결과")
```
